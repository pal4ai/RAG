{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for building RAG pipeline using LLMs - Chat History, Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers:\n",
    "    - RAG QA pipeline using LLMs\n",
    "    - Dataset - latest articles on similar topic - Christopher nolan movies\n",
    "    - Added citations to prevent hallucinations\n",
    "    - Added Chat history "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Required Installations\n",
    "#### pip install langchain\n",
    "#### pip install 'langchain[llms]' (for mac)\n",
    "#### pip install tiktoken  - openAi tokenizer\n",
    "#### export OPENAI_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "from langchain import PromptTemplate, OpenAI, LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PDF data and Convert it using Pymupdf Library from Lang Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyMuPDFLoader RETURNS ONE DOCUMENT PER PAGE\n",
    "- PyPDF- Load PDF using pypdf into array of documents, where each document contains the page content and metadata with page number.\n",
    "- Refer : https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read PDF input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf_input(file_path):\n",
    "    pdf_search = Path(file_path).glob(\"*.pdf\")\n",
    "    pdf_files  = [str(file.absolute()) for file in pdf_search]\n",
    "    print('Total PDF files',len(pdf_files))\n",
    "    pages = []\n",
    "    for pdf in pdf_files:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        pages.extend(loader.load_and_split())\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PDF files 5\n",
      "Length of pages 82\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "file_path='<data-path>'\n",
    "pages = read_pdf_input(file_path)\n",
    "print('Length of pages', len(pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATA STORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Embed the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_model = OpenAIEmbeddings(openai_api_key=\"<open-ai-key>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store : FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(pages, embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RETRIEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "#retriever = db.as_retriever(search_type=\"mmr\")\n",
    "#retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- retriever = db.as_retriever(search_kwargs={\"k\": 1}) -> For retrieving top k=1 results\n",
    "- retriever = db.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": .5}) -> For returning greater than 0.5 similarity score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. QA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Adding Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for adding citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_template = \"\"\" You are QA assistant. You are given a question and a dictionary.\n",
    "You need to generate the answer and cite the sentences used in generating the answer.\n",
    "The key from dictionary is the citation and the value from the dictionary is the context to generate the answer for the question. \n",
    "\n",
    "- Try your best to list the citations\n",
    "- If you do not find the answer, say politely that you don't know.\n",
    "- Do not generate false information.\n",
    "- Do not combine multiple sources, list them separately like [src_1][src_2]\n",
    "\n",
    "Below is an example:\n",
    "question : 'When did Roman Empire fall?'\n",
    "dictionary: article4.pdf_Page2: The western empire suffered several Gothic invasions and, in AD 455, was sacked by Vandals. Rome continued to decline after that until AD 476 when the western Roman Empire came to an end.\n",
    "Answer: 476 CE [article4.pdf_Page2]\n",
    "\n",
    "Use the dictionary: {dictionary} for the Question: {question} to generate the answer.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, OpenAI, LLMChain\n",
    "#reader_prompt = PromptTemplate(template=reader_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0,openai_api_key=\"<open-ai-key>\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create key: value pair of source and context for citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(docs):\n",
    "    result_dict={}\n",
    "    for doc in docs:\n",
    "        source_page = doc.metadata['source'].split(\"/\")[-1] + '_Page' + str (doc.metadata['page']+1)\n",
    "        result_dict[source_page]=doc.page_content\n",
    "    return result_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to generate answer and give citations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_reader(ques, llm, reader_template,retriever):\n",
    "    \n",
    "    #1. Generate the prompt using prompt template\n",
    "    reader_prompt = PromptTemplate(template=reader_template, input_variables=[\"dictionary\", \"question\"])\n",
    "    \n",
    "    #2. Use LLM chain to create llm instance with the llm model and the prompt\n",
    "    llm_chain = LLMChain(prompt=reader_prompt, llm=llm)\n",
    "    \n",
    "    #3. Retrieve relevant documents from the retriever for the input query\n",
    "    docs= retriever.get_relevant_documents(ques)\n",
    "    \n",
    "    #4. Data preprocess function to add source id for citations : return dict with source id as key and page content as value\n",
    "    preprocess_docs = data_preprocess(docs)\n",
    "    \n",
    "    #5. Pass the retrieved documents as the dictionary and the input query to the LLM Chain created in step 2\n",
    "    result = llm_chain.predict(dictionary=preprocess_docs, question=ques)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Answer from Reader ----------------\n",
      "Question:  Who is Christopher Nolan?\n",
      "Answer:  Christopher Nolan is a British film director and writer known for his noirish visual aesthetic and unconventional narratives [article3.pdf_Page1]. He was raised by an American mother and a British father and spent time in both Chicago and London [article3.pdf_Page1]. Nolan became interested in moviemaking from a young age and would use his father's Super-8 camera to make shorts [article3.pdf_Page1]. His breakthrough film was \"Memento\" in 2000, which used a reverse-order story line to mirror the fractured mental state of its protagonist [article3.pdf_Page1]. Nolan gained further recognition with his film \"Batman Begins\" in 2005, which focused on the origins of the superhero and had a darker and more realistic tone compared to previous Batman films [article3.pdf_Page1].\n",
      "\n",
      "\n",
      "Question:  Which is Christopher Nolan's latest movie?\n",
      "Answer:  I'm sorry, but I don't have the information to answer your question.\n",
      "\n",
      "\n",
      "Question:  What actors did he work with?\n",
      "Answer:  Cillian Murphy [article3.pdf_Page2][article5.pdf_Page8]\n",
      "Heath Ledger [article3.pdf_Page2]\n",
      "Leonardo DiCaprio [article3.pdf_Page2]\n",
      "Joseph Gordon-Levitt [article3.pdf_Page2]\n",
      "Matthew McConaughey [article3.pdf_Page2]\n",
      "\n",
      "\n",
      "Question:  Can you provide list of more actors he has worked with?\n",
      "Answer:  I'm sorry, but I don't have the information to answer your question.\n",
      "\n",
      "\n",
      "Question:  How did he begin his career?\n",
      "Answer:  Christopher Nolan began his career by directing corporate and industrial training videos while simultaneously working on his first full-length release, \"Following\" (1998) [article3.pdf_Page1]. He was influenced by George Lucas's Star Wars trilogy and Ridley Scott's dystopian films [article3.pdf_Page1]. \"Following\" centered on a writer going to dangerous lengths to find inspiration and took Nolan 14 months to complete [article3.pdf_Page1]. On the strength of its success on the festival circuit, Nolan and his producer wife moved to Hollywood [article3.pdf_Page1].\n",
      "\n",
      "\n",
      "Question:  How is he as a person?\n",
      "Answer:  I'm sorry, but I don't have enough information to answer the question.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------- Answer from Reader ----------------')\n",
    "ques = \"Who is Christopher Nolan?\"\n",
    "ans = qa_reader(ques, llm,reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"Which is Christopher Nolan's latest movie?\"\n",
    "ans = qa_reader(ques, llm,reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"What actors did he work with?\"\n",
    "ans = qa_reader(ques, llm,reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"Can you provide list of more actors he has worked with?\"\n",
    "ans = qa_reader(ques, llm,reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"How did he begin his career?\"\n",
    "ans = qa_reader(ques, llm, reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"How is he as a person?\"\n",
    "ans = qa_reader(ques, llm, reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Adding Conversational History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt for adding conversational history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_template =\"\"\"As a Question answering assistant, generate a new question based on the asked question and the conversational history - History.\n",
    "History will be passed as a list.\n",
    "The string will be in format:\n",
    "'Question: '+ asked question + \" Answer: \"+ answer\n",
    "Your task is to fetch the text after keyword 'Question: ' and before keyword \"Answer: \" from History and this will be the asked question\n",
    "by the user. You need to then generate a new question using the conversational history and below guidelines:\n",
    "- Conversational history is ordered from least recent to most recent. Weight most recent history the most.\n",
    "- If the asked question is not related to the conversational history, do not consider the history while answering and \n",
    "return the original question.\n",
    "- Only generate a single query.\n",
    "- If multiple options exist for the query, do not separate them by OR and do not ask the user to select. Just pick any single query.\n",
    "- Do not ask clarifying questions, if you are not sure about the new query, just output the original question.\n",
    "\n",
    "History : {history}\n",
    "asked question : {ques}\n",
    "New Question: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility Function for adding conversational history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_conversationHistory(ques, llm, conversational_template,history):\n",
    "    conversational_prompt = PromptTemplate(template=conversational_template, input_variables=[\"history\",\"ques\"])\n",
    "    llm_chain = LLMChain(prompt=conversational_prompt, llm=llm)\n",
    "    #docs= retriever.get_relevant_documents(ques)\n",
    "    new_ques = llm_chain.predict(history=history,ques=ques)\n",
    "    return new_ques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for adding:\n",
    " - Conversational History\n",
    " - Citations while generating answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store history\n",
    "history =[]\n",
    "def pipeline(ques, llm, reader_template,conversational_template,retriever,history):\n",
    "    \n",
    "    # Generate new question based on previous history\n",
    "    new_ques = qa_conversationHistory(ques, llm, conversational_template,history)\n",
    "    \n",
    "    # Generate answer for the new question and add citations\n",
    "    ans = qa_reader(new_ques, llm, reader_template,retriever)\n",
    "    \n",
    "    # Add the new question and answer in the history \n",
    "    inp = 'Question: '+ new_ques + \" Answer: \"+ ans\n",
    "    history.append(inp)\n",
    "    return ques,new_ques,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Answer with conversation history and citations ----------------\n",
      "Initial History  []\n",
      "Question:  What is the movie Dunkirk about?\n",
      "New Question:  What is the movie Dunkirk about?\n",
      "Answer:  The movie Dunkirk is about the British evacuation of France in 1940 during World War II [article1.pdf_Page8]. It depicts the efforts to rescue 338,000 Allied soldiers who were trapped on the beaches of Dunkirk [article2.pdf_Page7]. The film intercuts three narrative timelines of different lengths, resulting in surprising twists and turns in the story [article1.pdf_Page8]. It immerses audiences into the overpowering desperation to survive during war [article2.pdf_Page7]. The movie showcases the visual poetry of a pilot standing before the burning wreckage of his plane at twilight on a beach, symbolizing British resolve in the face of defeat [article2.pdf_Page7].\n",
      "\n",
      "\n",
      "Question:  Who was the main actor in this movie?\n",
      "New Question:  Who was the main actor in the movie Dunkirk?\n",
      "Answer:  Harry Styles [article4.pdf_Page5]\n",
      "\n",
      "\n",
      "Question:  Who is Christopher Nolan?\n",
      "New Question:  Who is Christopher Nolan?\n",
      "Answer:  Christopher Nolan is a British film director and writer known for his noirish visual aesthetic and unconventional narratives [article3.pdf_Page1]. He was raised by an American mother and a British father and spent time in both Chicago and London [article3.pdf_Page1]. Nolan became interested in moviemaking from a young age and would use his father's Super-8 camera to make shorts [article3.pdf_Page1]. His breakthrough film was \"Memento\" in 2000, which used a reverse-order story line to mirror the fractured mental state of its protagonist [article3.pdf_Page1]. Nolan gained further recognition with his film \"Batman Begins\" in 2005, which focused on the origins of the superhero and had a darker and more realistic tone compared to previous Batman films [article3.pdf_Page1].\n",
      "\n",
      "\n",
      "Question:  What is his latest movie?\n",
      "New Question:  New Question: What is Christopher Nolan's latest movie?\n",
      "Answer:  I'm sorry, but I don't know the answer to the question.\n",
      "\n",
      "\n",
      "Question:  How did he begin his career?\n",
      "New Question:  How did Christopher Nolan begin his career?\n",
      "Answer:  Christopher Nolan began his career by directing corporate and industrial training videos while working on his first full-length release, \"Following\" (1998). He used his father's Super-8 camera to make shorts and was influenced by George Lucas's Star Wars trilogy and Ridley Scott's dystopian films [article3.pdf_Page1]. \"Following\" centered on a writer going to dangerous lengths to find inspiration and took Nolan 14 months to complete. It was successful on the festival circuit and led him to move to Hollywood [article3.pdf_Page1].\n",
      "\n",
      "\n",
      "Question:  Has he won any awards?\n",
      "Answer:  I'm sorry, but I don't have enough information to answer the question.\n",
      "\n",
      "\n",
      "Question:  How is he as a person?\n",
      "New Question:  How would you describe Christopher Nolan as a person?\n",
      "Answer:  I'm sorry, but I don't have enough information to answer the question.\n",
      "\n",
      "\n",
      "Question:  What was his first movie?\n",
      "New Question:  What was Christopher Nolan's first movie?\n",
      "Answer:  Following (1998) [article3.pdf_Page1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history =[]\n",
    "print('---------------- Answer with conversation history and citations ----------------')\n",
    "print('Initial History ', history)\n",
    "\n",
    "ques = \"What is the movie Dunkirk about?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "ques = \"Who was the main actor in this movie?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "ques = \"Who is Christopher Nolan?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "ques = \"What is his latest movie?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "ques = \"How did he begin his career?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"Has he won any awards?\"\n",
    "ans = qa_reader(ques, llm, reader_template,retriever)\n",
    "print('Question: ',ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"How is he as a person?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n",
    "ques = \"What was his first movie?\"\n",
    "ques,new_ques,ans = pipeline(ques, llm, reader_template,conversational_template,retriever,history)\n",
    "print('Question: ',ques)\n",
    "print('New Question: ',new_ques)\n",
    "print('Answer: ',ans)\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pal4ai",
   "language": "python",
   "name": "pal4ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
